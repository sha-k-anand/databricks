%python
df = spark.read.load('abfss://tpch-sf1000-consolidated@tpchdata.dfs.core.windows.net/SUPPLIER/', format='parquet')
df2 = df.write.format("delta").save('abfss://tpch-sf1000-databricks-deltalake@tpchdata.dfs.core.windows.net/SUPPLIER/')




%python
df = spark.read.load('abfss://tpch-sf1000-consolidated@tpchdata.dfs.core.windows.net/SUPPLIER/', format='parquet')
display(df.limit(10))

df.write.format("delta").partitionBy("S_NATIONKEY").save("abfss://zztest@tpchdata.dfs.core.windows.net/Delta_SUPPLIER_part1/")

%sql
CREATE TABLE zzDelta_SUPPLIER_part1 
(
S_SUPPKEY bigint, 
S_NAME string,
S_ADDRESS string,
S_NATIONKEY bigint,
S_PHONE string,
S_ACCTBAL decimal(9,2) ,
S_COMMENT string
)
USING DELTA  PARTITIONED BY (S_NATIONKEY) OPTIONS (path 'abfss://zztest@tpchdata.dfs.core.windows.net/Delta_SUPPLIER_part1/')


%sql
CREATE TABLE zztest001  USING DELTA  OPTIONS (path 'abfss://zztest@tpchdata.dfs.core.windows.net/Delta_SUPPLIER_part1/')



